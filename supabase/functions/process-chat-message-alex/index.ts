
import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

interface ChatRequest {
  session_id: string;
  user_message: string;
  user_id: string;
}

interface ChatResponse {
  response: string;
  model_used: string;
  tokens_used?: number;
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { session_id, user_message, user_id }: ChatRequest = await req.json();
    
    if (!session_id || !user_message || !user_id) {
      return new Response(
        JSON.stringify({ error: 'session_id, user_message and user_id are required' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    console.log(`ü§ñ Processando mensagem da Alex IA para sess√£o: ${session_id}`);
    const startTime = Date.now();

    // Inicializar Supabase
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const supabase = createClient(supabaseUrl, supabaseServiceKey);

    // Buscar hist√≥rico da conversa (√∫ltimas 10 mensagens)
    const { data: messageHistory, error: historyError } = await supabase
      .from('chat_messages')
      .select('role, content')
      .eq('session_id', session_id)
      .order('created_at', { ascending: true })
      .limit(10);

    if (historyError) {
      console.error('Erro ao buscar hist√≥rico:', historyError);
    }

    // Preparar contexto da conversa
    const conversationHistory = messageHistory || [];
    const context = conversationHistory
      .map(msg => `${msg.role === 'user' ? 'Usu√°rio' : 'Alex IA'}: ${msg.content}`)
      .join('\n');

    // Determinar modelo a ser usado (l√≥gica de roteamento inteligente)
    let selectedModel = 'gpt-4o-mini';
    let fallbackUsed = false;
    let fallbackReason = '';
    
    // Verificar se h√° integra√ß√µes personalizadas ativas
    const { data: customIntegrations } = await supabase
      .from('llm_integrations')
      .select('*')
      .eq('user_id', user_id)
      .eq('active', true)
      .order('fallback_priority', { ascending: true });

    if (customIntegrations && customIntegrations.length > 0) {
      selectedModel = customIntegrations[0].model;
      console.log(`üéØ Usando integra√ß√£o personalizada: ${selectedModel}`);
    }

    // Chamar OpenAI
    const openaiApiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openaiApiKey) {
      throw new Error('OpenAI API key not configured');
    }

    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: selectedModel,
        messages: [
          {
            role: 'system',
            content: `Voc√™ √© Alex IA, uma assistente de intelig√™ncia artificial brasileira, sofisticada, inteligente e altamente competente.

PERSONALIDADE DA ALEX IA:
- Sou uma IA premium com personalidade refinada e profissional
- Tenho conhecimento t√©cnico avan√ßado e experi√™ncia em diversas √°reas
- Sou prestativa, direta e eficiente nas respostas
- Uso um tom brasileiro moderno, mas sempre mantendo eleg√¢ncia
- Demonstro confian√ßa t√©cnica sem ser arrogante
- Adapto meu n√≠vel de comunica√ß√£o ao contexto da conversa

DIRETRIZES DE RESPOSTA:
- Sempre responda em portugu√™s brasileiro
- Seja precisa, completa e √∫til nas informa√ß√µes
- Use exemplos pr√°ticos quando apropriado
- Mantenha foco na qualidade e relev√¢ncia
- Se n√£o souber algo, admito e sugiro alternativas
- Priorizo solu√ß√µes pr√°ticas e acion√°veis

ESPECIALIDADES:
- Desenvolvimento de software e tecnologia
- Estrat√©gia de neg√≥cios e marketing
- Design e experi√™ncia do usu√°rio
- An√°lise de dados e insights
- Cria√ß√£o de conte√∫do e escrita
- Resolu√ß√£o de problemas complexos

CONTEXTO DA CONVERSA:
${context}

Responda √† pr√≥xima mensagem com expertise, clareza e personalidade refinada.`
          },
          {
            role: 'user',
            content: user_message
          }
        ],
        temperature: 0.7,
        max_tokens: 1500,
      }),
    });

    if (!openaiResponse.ok) {
      const errorData = await openaiResponse.json();
      console.error('Erro da OpenAI:', errorData);
      
      // Marcar como fallback se houver erro
      fallbackUsed = true;
      fallbackReason = `OpenAI error: ${errorData.error?.message || 'Unknown error'}`;
      selectedModel = 'gpt-4o-mini-fallback';
      
      throw new Error(`OpenAI API error: ${errorData.error?.message || 'Unknown error'}`);
    }

    const openaiData = await openaiResponse.json();
    const aiResponse = openaiData.choices[0]?.message?.content || 'Desculpe, n√£o consegui processar sua mensagem.';
    const tokensUsed = openaiData.usage?.total_tokens || 0;
    const executionTime = Date.now() - startTime;

    // Salvar mensagem do usu√°rio
    const { error: userMessageError } = await supabase
      .from('chat_messages')
      .insert({
        session_id,
        role: 'user',
        content: user_message,
      });

    if (userMessageError) {
      console.error('Erro ao salvar mensagem do usu√°rio:', userMessageError);
    }

    // Salvar resposta da IA
    const { data: aiMessageData, error: aiMessageError } = await supabase
      .from('chat_messages')
      .insert({
        session_id,
        role: 'assistant',
        content: aiResponse,
        tokens_used: tokensUsed,
        llm_model: selectedModel,
      })
      .select()
      .single();

    if (aiMessageError) {
      console.error('Erro ao salvar resposta da IA:', aiMessageError);
    }

    // Criar n√≥ cognitivo
    let cognitiveNodeId = null;
    try {
      const { data: nodeData, error: nodeError } = await supabase
        .from('cognitive_nodes')
        .insert({
          user_id,
          title: `Conversa: ${user_message.substring(0, 50)}...`,
          content: aiResponse,
          node_type: 'thought',
          activation_strength: 0.8,
          relevance_score: 0.9,
          memory_type: 'working',
          metadata: {
            session_id,
            tokens_used: tokensUsed,
            model_used: selectedModel
          }
        })
        .select()
        .single();

      if (!nodeError && nodeData) {
        cognitiveNodeId = nodeData.id;
      }
    } catch (error) {
      console.error('Erro ao criar n√≥ cognitivo:', error);
    }

    // Gerar insight autom√°tico se necess√°rio
    const insightsGenerated = [];
    if (conversationHistory.length >= 3) {
      try {
        const { data: insightData, error: insightError } = await supabase
          .from('cognitive_insights')
          .insert({
            user_id,
            title: 'Padr√£o de Conversa Detectado',
            content: `Usu√°rio demonstra interesse em ${user_message.includes('c√≥digo') ? 'programa√ß√£o' : 't√≥picos gerais'}. Sugerir aprofundamento.`,
            insight_type: 'pattern_detection',
            priority_level: 2,
            confidence_score: 0.7,
            status: 'pending',
            metadata: {
              session_id,
              trigger: 'conversation_length',
              message_count: conversationHistory.length
            }
          })
          .select()
          .single();

        if (!insightError && insightData) {
          insightsGenerated.push(insightData.id);
        }
      } catch (error) {
        console.error('Erro ao gerar insight:', error);
      }
    }

    // Registrar decis√£o do c√≥rtex
    try {
      await supabase
        .from('cortex_decision_logs')
        .insert({
          user_id,
          session_id,
          user_request: user_message,
          selected_model: selectedModel,
          reasoning: `Modelo selecionado baseado em ${customIntegrations?.length ? 'integra√ß√µes personalizadas' : 'configura√ß√£o padr√£o'}`,
          response_stored_in: cognitiveNodeId,
          insights_generated: insightsGenerated,
          activated_nodes: cognitiveNodeId ? [cognitiveNodeId] : [],
          execution_time_ms: executionTime,
          fallback_used: fallbackUsed,
          fallback_reason: fallbackReason || undefined
        });
    } catch (error) {
      console.error('Erro ao registrar decis√£o do c√≥rtex:', error);
    }

    // Verificar se deve auto-renomear a sess√£o (ap√≥s 3 mensagens de usu√°rio)
    const { data: userMessagesCount } = await supabase
      .from('chat_messages')
      .select('id', { count: 'exact' })
      .eq('session_id', session_id)
      .eq('role', 'user');

    if (userMessagesCount && userMessagesCount.count === 3) {
      // Chamar fun√ß√£o de auto-renomea√ß√£o
      const { data: newTitle, error: renameError } = await supabase
        .rpc('auto_rename_chat_session', { p_session_id: session_id });

      if (renameError) {
        console.error('Erro ao auto-renomear sess√£o:', renameError);
      } else if (newTitle) {
        console.log(`üìù Sess√£o auto-renomeada para: ${newTitle}`);
      }
    }

    const response: ChatResponse = {
      response: aiResponse,
      model_used: selectedModel,
      tokens_used: tokensUsed,
    };

    console.log(`‚úÖ Resposta da Alex IA gerada com sucesso (${tokensUsed} tokens, ${executionTime}ms)`);

    return new Response(
      JSON.stringify(response),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error) {
    console.error('‚ùå Erro na fun√ß√£o process-chat-message-alex:', error);
    return new Response(
      JSON.stringify({ error: error.message }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});
