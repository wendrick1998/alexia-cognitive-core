/**
 * @modified_by Manus AI
 * @date 1 de junho de 2025
 * @description Documenta√ß√£o completa dos aprimoramentos do sistema multi-LLM
 * Inclui instru√ß√µes de uso, integra√ß√£o e manuten√ß√£o dos novos recursos
 */

# Documenta√ß√£o dos Aprimoramentos do Sistema Multi-LLM

## √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Sistema de Feedback Ativo](#sistema-de-feedback-ativo)
3. [CortexCache (Cache Sem√¢ntico)](#cortexcache-cache-sem√¢ntico)
4. [Logs Inteligentes por Modelo](#logs-inteligentes-por-modelo)
5. [Integra√ß√£o com Supabase](#integra√ß√£o-com-supabase)
6. [Integra√ß√£o com Lovable](#integra√ß√£o-com-lovable)
7. [Manuten√ß√£o e Monitoramento](#manuten√ß√£o-e-monitoramento)
8. [Troubleshooting](#troubleshooting)

## Vis√£o Geral

Este documento detalha os tr√™s principais aprimoramentos implementados no sistema multi-LLM do Alex iA:

1. **Sistema de Feedback Ativo**: Coleta feedback do usu√°rio (üëçüëé e escala 1-5) para melhorar o roteamento entre modelos.
2. **CortexCache**: Sistema de cache sem√¢ntico que evita chamadas redundantes √†s APIs de LLM.
3. **Logs Inteligentes**: Registro detalhado de m√©tricas por modelo, incluindo tempo, custo e fallback.

Estes aprimoramentos trabalham em conjunto para melhorar a experi√™ncia do usu√°rio, reduzir custos e otimizar o desempenho do sistema.

## Sistema de Feedback Ativo

### Componentes Principais

- **FeedbackSystem.tsx**: Componente React que exibe bot√µes üëçüëé e escala 1-5 opcional.
- **FeedbackBatchProcessor.ts**: Servi√ßo que processa feedback em lote e atualiza prefer√™ncias do orquestrador.
- **Tabelas Supabase**: `llm_feedback`, `llm_orchestrator_preferences`, `llm_feedback_batch_processing`.

### Como Usar

1. **Adicionar o componente de feedback ap√≥s respostas LLM**:

```tsx
import { FeedbackSystem } from '@/components/FeedbackSystem';
import { useLLMRouter } from '@/hooks/useLLMRouter';

const ChatMessage = ({ message }) => {
  const { recordResponseContext } = useLLMRouter();
  
  // Registrar contexto da resposta para feedback
  const responseContext = {
    question: message.question,
    answer: message.answer,
    modelName: message.modelName,
    provider: message.provider,
    usedFallback: message.usedFallback,
    responseTime: message.responseTime,
    tokensUsed: message.tokensUsed,
    timestamp: new Date(),
    sessionId: 'session-123',
    userId: 'user-456'
  };
  
  return (
    <div className="message">
      <div className="content">{message.answer}</div>
      <FeedbackSystem context={responseContext} />
    </div>
  );
};
```

2. **Configurar processamento em lote**:

```tsx
import { FeedbackBatchProcessor } from '@/services/FeedbackBatchProcessor';

// Executar periodicamente (ex: a cada 24h)
const processFeedback = async () => {
  const processor = new FeedbackBatchProcessor();
  await processor.startBatchProcessing();
  const preferencesUpdated = await processor.processFeedback();
  console.log(`${preferencesUpdated} prefer√™ncias atualizadas`);
};
```

3. **Verificar prefer√™ncias atualizadas**:

As prefer√™ncias atualizadas ser√£o automaticamente consideradas pelo hook `useLLMRouter` na pr√≥xima inicializa√ß√£o.

### M√©tricas e Monitoramento

- **Taxa de feedback**: Porcentagem de respostas que recebem feedback.
- **Distribui√ß√£o de avalia√ß√µes**: Propor√ß√£o de üëç vs üëé e distribui√ß√£o na escala 1-5.
- **Impacto no roteamento**: Mudan√ßas nas prefer√™ncias do orquestrador ao longo do tempo.

## CortexCache (Cache Sem√¢ntico)

### Componentes Principais

- **SemanticCache.ts**: Servi√ßo que gerencia o cache sem√¢ntico de respostas LLM.
- **Tabelas Supabase**: `llm_response_cache`, `llm_cache_metrics`.
- **Extens√£o pgvector**: Utilizada para armazenamento e busca de embeddings.

### Como Usar

1. **Inicializar o cache**:

```tsx
import { SemanticCache } from '@/services/SemanticCache';

const cache = new SemanticCache({
  similarityThreshold: 0.85, // Limiar de similaridade (0-1)
  maxCacheAge: 7 * 24 * 60 * 60 * 1000, // 7 dias em ms
  userId: 'user-123'
});
```

2. **Verificar cache antes de chamar LLM**:

```tsx
const handleQuestion = async (question: string) => {
  // Determinar tipo de tarefa
  const taskType = inferTaskType(question);
  
  // Verificar cache
  const cachedResponse = await cache.getCachedResponse(question, taskType);
  
  if (cachedResponse) {
    // Usar resposta em cache
    return {
      answer: cachedResponse,
      fromCache: true
    };
  }
  
  // Se n√£o encontrou no cache, chamar LLM
  const { modelConfig } = llmRouter.routeByTask(taskType);
  const response = await callLLM(question, modelConfig);
  
  // Adicionar ao cache
  await cache.cacheResponse(
    question,
    response.answer,
    taskType,
    modelConfig.modelName,
    modelConfig.provider,
    response.tokensUsed
  );
  
  return {
    answer: response.answer,
    fromCache: false
  };
};
```

3. **Manuten√ß√£o do cache**:

```tsx
// Limpar cache expirado (executar periodicamente)
const cleanupCache = async () => {
  const itemsRemoved = await cache.cleanupExpiredCache();
  console.log(`${itemsRemoved} itens de cache expirados removidos`);
};

// Obter estat√≠sticas de uso do cache
const getCacheStats = async () => {
  const stats = await cache.getCacheStats();
  console.log(`Taxa de hit: ${stats.hitRate * 100}%`);
  console.log(`Tokens economizados em m√©dia: ${stats.averageTokensSaved}`);
};
```

### M√©tricas e Monitoramento

- **Taxa de hit**: Porcentagem de consultas atendidas pelo cache.
- **Tokens economizados**: Quantidade de tokens (e custo) economizados pelo cache.
- **Distribui√ß√£o de similaridade**: Histograma de scores de similaridade para hits de cache.

## Logs Inteligentes por Modelo

### Componentes Principais

- **LLMLogger.ts**: Servi√ßo que registra e analisa m√©tricas detalhadas por modelo.
- **Tabelas Supabase**: `llm_call_logs`, `llm_model_metrics`.
- **Fun√ß√£o cron**: Agrega√ß√£o di√°ria de m√©tricas para an√°lise de tend√™ncias.

### Como Usar

1. **Inicializar o logger**:

```tsx
import { LLMLogger } from '@/services/LLMLogger';

const logger = new LLMLogger({
  enableRealTimeLogging: true,
  batchSize: 10,
  userId: 'user-123',
  sessionId: 'session-456'
});
```

2. **Registrar chamadas LLM**:

```tsx
const callLLMWithLogging = async (question: string, modelConfig) => {
  // Iniciar log
  const callId = await logger.logStart(
    modelConfig.modelName,
    modelConfig.provider,
    taskType,
    question,
    estimatedInputTokens
  );
  
  try {
    // Chamar LLM
    const startTime = Date.now();
    const response = await callLLM(question, modelConfig);
    const responseTime = Date.now() - startTime;
    
    // Finalizar log com sucesso
    await logger.logEnd(
      callId,
      response.answer.length,
      response.tokensOutput,
      'success',
      {
        usedFallback: false,
        cacheHit: false
      }
    );
    
    return response;
  } catch (error) {
    // Finalizar log com erro
    await logger.logEnd(
      callId,
      0,
      0,
      'error',
      {
        errorMessage: error.message
      }
    );
    
    // Tentar fallback
    const fallbackResponse = await callFallbackLLM(question);
    
    // Registrar uso de fallback
    await logger.logEnd(
      callId,
      fallbackResponse.answer.length,
      fallbackResponse.tokensOutput,
      'success',
      {
        usedFallback: true,
        fallbackReason: 'primary_model_error',
        fallbackModel: fallbackResponse.modelName
      }
    );
    
    return fallbackResponse;
  }
};
```

3. **Analisar m√©tricas**:

```tsx
// Obter m√©tricas por modelo
const getModelMetrics = async () => {
  const startDate = new Date();
  startDate.setDate(startDate.getDate() - 30); // √öltimos 30 dias
  
  const metrics = await logger.getMetricsByModel(startDate);
  
  // Exibir m√©tricas
  metrics.forEach(metric => {
    console.log(`Modelo: ${metric.modelName} (${metric.provider})`);
    console.log(`Chamadas totais: ${metric.totalCalls}`);
    console.log(`Taxa de sucesso: ${metric.successRate * 100}%`);
    console.log(`Tempo m√©dio de resposta: ${metric.avgResponseTime}ms`);
    console.log(`Custo total: $${metric.totalCost.toFixed(2)}`);
    console.log(`Taxa de fallback: ${metric.fallbackRate * 100}%`);
    console.log(`Taxa de cache hit: ${metric.cacheHitRate * 100}%`);
    console.log('---');
  });
};

// Obter m√©tricas de fallback
const getFallbackInsights = async () => {
  const fallbackMetrics = await logger.getFallbackMetrics();
  
  console.log(`Total de fallbacks: ${fallbackMetrics.totalFallbacks}`);
  console.log('Raz√µes de fallback:');
  Object.entries(fallbackMetrics.fallbacksByReason).forEach(([reason, count]) => {
    console.log(`- ${reason}: ${count}`);
  });
};

// Obter m√©tricas de custo
const getCostInsights = async () => {
  const costMetrics = await logger.getCostMetrics('week');
  
  console.log(`Custo total: $${costMetrics.totalCost.toFixed(2)}`);
  console.log('Custo por modelo:');
  Object.entries(costMetrics.costByModel).forEach(([model, cost]) => {
    console.log(`- ${model}: $${cost.toFixed(2)}`);
  });
};
```

### M√©tricas e Monitoramento

- **Performance**: Tempo m√©dio de resposta, P95, P99 por modelo.
- **Confiabilidade**: Taxa de sucesso, taxa de fallback, raz√µes de fallback.
- **Custo**: Custo total, custo por modelo, custo por tipo de tarefa.
- **Tend√™ncias**: Evolu√ß√£o das m√©tricas ao longo do tempo.

## Integra√ß√£o com Supabase

### Configura√ß√£o Inicial

1. **Aplicar schemas SQL**:

Acesse o Editor SQL do Supabase e execute os seguintes scripts:

- `/supabase/migrations/20250601_llm_feedback_schema.sql`
- `/supabase/migrations/20250601_semantic_cache_schema.sql`
- `/supabase/migrations/20250601_llm_logs_schema.sql`

2. **Habilitar extens√£o pgvector**:

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

3. **Configurar vari√°veis de ambiente**:

```
VITE_SUPABASE_URL=https://seu-projeto.supabase.co
VITE_SUPABASE_ANON_KEY=sua-chave-anon
VITE_OPENAI_API_KEY=sua-chave-openai
```

### Manuten√ß√£o do Banco de Dados

- **Limpeza peri√≥dica**: Configurar jobs para remover dados antigos e manter o tamanho do banco gerenci√°vel.
- **Backup**: Configurar backups regulares das tabelas cr√≠ticas.
- **Monitoramento**: Verificar regularmente o crescimento das tabelas e performance das queries.

## Integra√ß√£o com Lovable

### Sincroniza√ß√£o com GitHub

1. **Commit dos arquivos**:

```bash
git add src/components/FeedbackSystem.tsx
git add src/services/FeedbackBatchProcessor.ts
git add src/services/SemanticCache.ts
git add src/services/LLMLogger.ts
git add src/hooks/useLLMRouter.tsx
git add supabase/migrations/*.sql
git commit -m "feat: add feedback system, semantic cache and intelligent logs"
git push origin main
```

2. **Sincronizar Lovable com GitHub**:

- Abra o Lovable 2.0
- Selecione "Importar Projeto"
- Conecte ao GitHub e selecione o reposit√≥rio `alexia-cognitive-core`
- Aguarde a sincroniza√ß√£o completa

### Uso no Lovable

1. **Adicionar componente de feedback**:

- Navegue at√© o componente de chat ou resposta LLM
- Adicione o componente `FeedbackSystem` ap√≥s cada resposta

2. **Integrar cache sem√¢ntico**:

- Modifique o fluxo de processamento de perguntas para verificar o cache antes de chamar LLM
- Adicione l√≥gica para armazenar respostas no cache

3. **Implementar logging**:

- Adicione chamadas ao `LLMLogger` nos pontos de entrada e sa√≠da de chamadas LLM
- Crie um dashboard para visualizar m√©tricas

## Manuten√ß√£o e Monitoramento

### Tarefas Peri√≥dicas

1. **Processamento de feedback**:

Configurar um job para executar diariamente:

```typescript
// Exemplo com setInterval (em produ√ß√£o, usar um scheduler mais robusto)
setInterval(async () => {
  const processor = new FeedbackBatchProcessor();
  await processor.startBatchProcessing();
  await processor.processFeedback();
}, 24 * 60 * 60 * 1000); // 24 horas
```

2. **Limpeza de cache**:

```typescript
// Executar semanalmente
setInterval(async () => {
  const cache = new SemanticCache();
  await cache.cleanupExpiredCache();
}, 7 * 24 * 60 * 60 * 1000); // 7 dias
```

3. **An√°lise de m√©tricas**:

```typescript
// Gerar relat√≥rio semanal
const generateWeeklyReport = async () => {
  const logger = new LLMLogger();
  
  // Definir per√≠odo
  const endDate = new Date();
  const startDate = new Date();
  startDate.setDate(startDate.getDate() - 7);
  
  // Obter m√©tricas
  const modelMetrics = await logger.getMetricsByModel(startDate, endDate);
  const fallbackMetrics = await logger.getFallbackMetrics();
  const costMetrics = await logger.getCostMetrics('day', startDate, endDate);
  
  // Gerar relat√≥rio
  const report = {
    period: {
      start: startDate.toISOString(),
      end: endDate.toISOString()
    },
    models: modelMetrics,
    fallback: fallbackMetrics,
    cost: costMetrics
  };
  
  // Salvar ou enviar relat√≥rio
  await saveWeeklyReport(report);
};
```

### Alertas

Configurar alertas para situa√ß√µes cr√≠ticas:

1. **Custo excessivo**:
   - Alerta quando o custo di√°rio exceder um limite predefinido
   - Exemplo: > $10/dia

2. **Taxa de fallback alta**:
   - Alerta quando a taxa de fallback exceder um limite
   - Exemplo: > 10% das chamadas

3. **Tempo de resposta degradado**:
   - Alerta quando o P95 do tempo de resposta aumentar significativamente
   - Exemplo: > 50% acima da m√©dia hist√≥rica

## Troubleshooting

### Problemas Comuns

1. **Feedback n√£o est√° sendo registrado**:
   - Verificar conex√£o com Supabase
   - Verificar permiss√µes da tabela `llm_feedback`
   - Verificar erros no console do navegador

2. **Cache sem√¢ntico n√£o est√° funcionando**:
   - Verificar se a extens√£o pgvector est√° habilitada
   - Verificar se os embeddings est√£o sendo gerados corretamente
   - Verificar o limiar de similaridade (pode estar muito alto)

3. **Logs n√£o est√£o sendo registrados**:
   - Verificar conex√£o com Supabase
   - Verificar se o flush autom√°tico est√° funcionando
   - Verificar erros no console

4. **Processamento em batch n√£o est√° atualizando prefer√™ncias**:
   - Verificar se h√° feedback suficiente para an√°lise estat√≠stica
   - Verificar permiss√µes da tabela `llm_orchestrator_preferences`
   - Verificar logs de erro do processador

### Diagn√≥stico

1. **Verificar conex√£o com Supabase**:

```typescript
const testSupabaseConnection = async () => {
  const supabase = createClient(
    import.meta.env.VITE_SUPABASE_URL as string,
    import.meta.env.VITE_SUPABASE_ANON_KEY as string
  );
  
  const { data, error } = await supabase.from('llm_feedback').select('count');
  
  if (error) {
    console.error('Erro de conex√£o com Supabase:', error);
    return false;
  }
  
  console.log('Conex√£o com Supabase OK');
  return true;
};
```

2. **Verificar gera√ß√£o de embeddings**:

```typescript
const testEmbeddingGeneration = async () => {
  const cache = new SemanticCache();
  const testText = 'Texto de teste para gera√ß√£o de embedding';
  
  try {
    const embedding = await cache['generateEmbedding'](testText);
    console.log(`Embedding gerado com sucesso. Dimens√£o: ${embedding.length}`);
    return true;
  } catch (error) {
    console.error('Erro na gera√ß√£o de embedding:', error);
    return false;
  }
};
```

3. **Verificar processamento de feedback**:

```typescript
const testFeedbackProcessing = async () => {
  const processor = new FeedbackBatchProcessor();
  
  try {
    await processor.startBatchProcessing();
    const updated = await processor.processFeedback();
    console.log(`Processamento de feedback OK. ${updated} prefer√™ncias atualizadas.`);
    return true;
  } catch (error) {
    console.error('Erro no processamento de feedback:', error);
    return false;
  }
};
```

### Recupera√ß√£o

1. **Reiniciar servi√ßos**:

```typescript
const resetServices = () => {
  // Limpar dados tempor√°rios
  localStorage.clear();
  
  // Reiniciar inst√¢ncias
  const logger = new LLMLogger();
  const cache = new SemanticCache();
  const processor = new FeedbackBatchProcessor();
  
  console.log('Servi√ßos reiniciados');
};
```

2. **Reconstruir √≠ndices**:

```sql
-- Reconstruir √≠ndice de embeddings
REINDEX INDEX idx_llm_response_cache_embedding;

-- Reconstruir outros √≠ndices
REINDEX TABLE llm_feedback;
REINDEX TABLE llm_call_logs;
```

3. **Limpar dados corrompidos**:

```typescript
const cleanupCorruptedData = async () => {
  const supabase = createClient(
    import.meta.env.VITE_SUPABASE_URL as string,
    import.meta.env.VITE_SUPABASE_ANON_KEY as string
  );
  
  // Remover logs com erros
  await supabase
    .from('llm_call_logs')
    .delete()
    .eq('status', 'error');
  
  // Remover embeddings nulos
  await supabase
    .from('llm_response_cache')
    .delete()
    .is('embedding', null);
  
  console.log('Dados corrompidos removidos');
};
```
